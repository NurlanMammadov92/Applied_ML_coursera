{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blight_model():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # Use the appropriate directory whenever it is necessary\n",
    "    train_df = pd.read_csv('train.csv', encoding = \"ISO-8859-1\")\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    address_df = pd.read_csv('addresses.csv')\n",
    "    latlons_df = pd.read_csv('latlons.csv')\n",
    "    \n",
    "    \n",
    "    train_df = train_df[(train_df['compliance'] == 0) | (train_df['compliance'] == 1)]\n",
    "    train_df = train_df[train_df['country'] == 'USA']\n",
    "    train_df = train_df[train_df['country'] == 'USA']\n",
    "    train_df = pd.merge(train_df, pd.merge(address_df, latlons_df, on = 'address'), on = 'ticket_id')\n",
    "    test_df = pd.merge(test_df, pd.merge(address_df, latlons_df, on = 'address'), on = 'ticket_id')\n",
    "    # Dropping the unnecessary columns\n",
    "    train_df.drop(['agency_name', 'inspector_name', 'violator_name', 'violation_street_number',\n",
    "                   'violation_street_name', 'violation_zip_code', 'violation_description', \n",
    "                   'admin_fee', 'state_fee', 'grafitti_status', 'ticket_issued_date',\n",
    "                   'hearing_date', 'country', 'address', \n",
    "                   # mailing related columns\n",
    "                   'mailing_address_str_number', 'mailing_address_str_name', 'city', 'state', 'zip_code',\n",
    "                   'non_us_str_code',\n",
    "                   # non-existent columns in test data\n",
    "                   'payment_date', 'payment_status', 'collection_status', 'balance_due',\n",
    "                   'payment_amount','compliance_detail'], axis = 1, inplace = True)\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(train_df['disposition'])\n",
    "    train_df['disposition'] = label_encoder.transform(train_df['disposition'])\n",
    "    test_df['disposition'] = label_encoder.fit_transform(test_df['disposition'])\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(train_df['violation_code'])\n",
    "    train_df['violation_code'] = label_encoder.transform(train_df['violation_code'])\n",
    "    test_df['violation_code'] = label_encoder.fit_transform(test_df['violation_code'])\n",
    "    \n",
    "    train_df['lat'] = train_df['lat'].fillna(train_df['lat'].mean())\n",
    "    train_df['lon'] = train_df['lon'].fillna(train_df['lon'].mean())\n",
    "    test_df['lat'] = test_df['lat'].fillna(test_df['lat'].mean())\n",
    "    test_df['lon'] = test_df['lon'].fillna(test_df['lon'].mean())\n",
    "    train_df_col_names = list(train_df.columns)\n",
    "    train_df_col_names.remove('compliance')\n",
    "    test_df = test_df[train_df_col_names]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_df.loc[:, train_df.columns != 'compliance'],\n",
    "                                                   train_df['compliance'], random_state = 0)\n",
    "    rfreg = RandomForestRegressor()\n",
    "    grid_params = {'n_estimators': [10, 100], 'max_depth': [None, 30]}\n",
    "    grid_cv = GridSearchCV(rfreg, param_grid = grid_params, scoring = 'roc_auc')\n",
    "    grid_cv.fit(X_train, y_train)\n",
    "    print('Grid best param: ', grid_cv.best_params_)\n",
    "    print('Grid best score (max. AUC): ', grid_cv.best_score_)\n",
    "    \n",
    "    prediction_df = pd.DataFrame(grid_cv.predict(test_df), index = test_df.ticket_id)\n",
    "    prediction_df = prediction_df.rename(columns = {0: 'probs. of fine payment'})\n",
    "    \n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blight_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
