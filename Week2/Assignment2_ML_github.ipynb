{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 15\n",
    "x = np.linspace(0,10,n) + np.random.randn(n)/5\n",
    "y = np.sin(x)+x/6 + np.random.randn(n)/10\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "\n",
    "# You can use this function to help you visualize the dataset by\n",
    "# plotting a scatterplot of the data points\n",
    "# in the training and test sets.\n",
    "def part1_scatter():\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib notebook\n",
    "    plt.figure()\n",
    "    plt.scatter(X_train, y_train, label='training data')\n",
    "    plt.scatter(X_test, y_test, label='test data')\n",
    "    plt.legend(loc=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    mylist = []\n",
    "    X_predict = pd.DataFrame()\n",
    "    for i in range(1, 10):\n",
    "        X_predict[i] = np.linspace(0, 10, 100)**i\n",
    "    for i in [1, 3, 6, 9]:\n",
    "        poly_obj = PolynomialFeatures(degree = i)\n",
    "        X_poly = poly_obj.fit_transform(x.reshape(-1,1))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state = 0)\n",
    "    \n",
    "        linreg = LinearRegression().fit(X_train, y_train)\n",
    "        a = np.ones(100)\n",
    "        pred_values = linreg.predict(np.column_stack((a,X_predict.loc[:,1:i])))\n",
    "        temp_pred_values = pred_values\n",
    "        mylist.append(temp_pred_values)\n",
    "    four_row_array = np.asarray(mylist)\n",
    "    return four_row_array\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one(degree_predictions):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib notebook\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(X_train, y_train, 'o', label='training data', markersize=10)\n",
    "    plt.plot(X_test, y_test, 'o', label='test data', markersize=10)\n",
    "    for i,degree in enumerate([1,3,6,9]):\n",
    "        plt.plot(np.linspace(0,10,100), degree_predictions[i], alpha=0.8, lw=2, label='degree={}'.format(degree))\n",
    "    plt.ylim(-1,2.5)\n",
    "    plt.legend(loc=4)\n",
    "\n",
    "plot_one(answer_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "\n",
    "    X_train_reshaped = X_train.reshape(X_train.size, 1)\n",
    "    X_test_reshaped = X_test.reshape(X_test.size, 1)\n",
    "    \n",
    "    r2_train, r2_test = [], []\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        poly = PolynomialFeatures(degree=i)\n",
    "        X_train_poly = poly.fit_transform(X_train_reshaped)\n",
    "        X_test_poly = poly.fit_transform(X_test_reshaped)\n",
    "        linreg = LinearRegression().fit(X_train_poly, y_train)\n",
    "        r2_train.append(linreg.score(X_train_poly, y_train))\n",
    "        r2_test.append(linreg.score(X_test_poly, y_test))\n",
    "        \n",
    "    return np.asarray(r2_train), np.asarray(r2_test)\n",
    "answer_two() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "    X_train_reshaped = X_train.reshape(X_train.size, 1)\n",
    "    X_test_reshaped = X_test.reshape(X_test.size, 1)\n",
    "    \n",
    "    r2_train, r2_test = [], []\n",
    "    for i in range(0, 10):\n",
    "        poly = PolynomialFeatures(degree=i)\n",
    "        X_train_poly = poly.fit_transform(X_train_reshaped)\n",
    "        X_test_poly = poly.fit_transform(X_test_reshaped)\n",
    "        linreg = LinearRegression().fit(X_train_poly, y_train)\n",
    "        r2_train.append(linreg.score(X_train_poly, y_train))\n",
    "        r2_test.append(linreg.score(X_test_poly, y_test))\n",
    "    array_r2_train = np.asarray(r2_train)\n",
    "    array_r2_test = np.asarray(r2_test)\n",
    "    under_fitting = np.where(array_r2_train == np.min(array_r2_train))[0][0]\n",
    "    over_fitting = np.where(array_r2_train == np.max(array_r2_train))[0][0]\n",
    "    good_generalization = np.where(array_r2_test == np.max(array_r2_test))[0][0]\n",
    "    return (under_fitting, over_fitting, good_generalization)\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_four():\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import Lasso, LinearRegression\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "    poly_obj = PolynomialFeatures(degree=12)\n",
    "    X_poly = poly_obj.fit_transform(x.reshape(-1,1))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state = 0)\n",
    "    linreg = LinearRegression().fit(X_train, y_train)\n",
    "    Linreg_r2score = r2_score(linreg.predict(X_test), y_test)\n",
    "    \n",
    "    lasso = Lasso(alpha = 0.01, max_iter = 10000).fit(X_train, y_train)\n",
    "    Lasso_r2score = r2_score(lasso.predict(X_test), y_test)\n",
    "\n",
    "    return (Linreg_r2score, Lasso_r2score)\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "mush_df = pd.read_csv('mushrooms.csv')\n",
    "mush_df2 = pd.get_dummies(mush_df)\n",
    "\n",
    "X_mush = mush_df2.iloc[:,2:]\n",
    "y_mush = mush_df2.iloc[:,1]\n",
    "\n",
    "# use the variables X_train2, y_train2 for Question 5\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_mush, y_mush, random_state=0)\n",
    "\n",
    "# For performance reasons in Questions 6 and 7, we will create a smaller version of the\n",
    "# entire mushroom dataset for use in those questions.  For simplicity we'll just re-use\n",
    "# the 25% test split created above as the representative subset.\n",
    "#\n",
    "# Use the variables X_subset, y_subset for Questions 6 and 7.\n",
    "X_subset = X_test2\n",
    "y_subset = y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_five():\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(random_state = 0).fit(X_train2, y_train2)\n",
    "    imp_features = clf.feature_importances_\n",
    "    new_dict = {}\n",
    "    for i in range(len(imp_features)):\n",
    "        new_dict[X_train2.columns[i]] = imp_features[i]\n",
    "  \n",
    "    sorted_new_dict = sorted(new_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    new_list = []\n",
    "    for i in range(5):\n",
    "        new_list.append(sorted_new_dict[:5][i][0])\n",
    "    new_list\n",
    "    return new_list\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import validation_curve\n",
    "\n",
    "    param_range = np.logspace(-4, 1, 6)\n",
    "\n",
    "    train_scores, test_scores = validation_curve(SVC(kernel = 'rbf', C = 1, random_state = 0), \n",
    "                                             X_subset, y_subset, scoring = 'accuracy',\n",
    "                                             param_name = 'gamma', param_range = param_range, cv = 3)\n",
    "    train_scores_mean = np.mean(train_scores, axis = 1)\n",
    "    test_scores_mean = np.mean(test_scores, axis = 1)\n",
    "    return (train_scores_mean, test_scores_mean)\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    # After plotting the validation curve over the parameter range (gamma values)\n",
    "    # and looking at the train_scores_mean & test_scores_mean arrays I have \n",
    "    # decided to make a following conclusion.\n",
    "    param_range = np.logspace(-4, 1, 6)\n",
    "    under_fitting_gamma = param_range[0]\n",
    "    over_fitting_gamma = param_range[5]\n",
    "    # last value of gamma where training score is 1 while test score is only 0.52\n",
    "    good_generalization_gamma = param_range[3]\n",
    "    # If we look at the train and test mean scores we can observe that both of the\n",
    "    # values are equal to 1.\n",
    "    return (under_fitting_gamma, over_fitting_gamma, good_generalization_gamma)\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
